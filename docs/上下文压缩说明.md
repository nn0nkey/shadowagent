# 上下文压缩机制说明

## 功能概述

上下文压缩机制用于智能管理长对话历史，避免上下文过长导致的问题：
- Token消耗过大
- LLM处理速度变慢
- 超出模型上下文限制

## 实现方式

### 1. 消息历史压缩

**触发条件**：
- 消息数量超过 `MAX_HISTORY_MESSAGES`（默认20条）
- 总字符数超过 `CONTEXT_SUMMARY_THRESHOLD`（默认10000字符）

**压缩策略**：
1. 保留系统消息
2. 保留最近的N条消息（默认5条）
3. 使用LLM总结中间的消息
4. 如果LLM总结失败，使用简单总结（提取关键信息）

**关键信息保留**：
- 工具调用记录
- FLAG相关内容
- 错误信息
- 成功操作

### 2. 工具输出压缩

**触发条件**：
- 工具输出超过 `TOOL_OUTPUT_THRESHOLD`（默认5000字符）

**压缩策略**：
1. 截断到阈值长度
2. 提取关键信息（FLAG、错误、成功）
3. 添加摘要提示

## 配置参数

在 `.env` 文件中配置：

```bash
# 上下文压缩
ENABLE_CONTEXT_COMPRESSION=true
CONTEXT_SUMMARY_THRESHOLD=10000  # 字符数阈值
MAX_HISTORY_MESSAGES=20          # 最大消息数

# 工具输出压缩
TOOL_OUTPUT_THRESHOLD=5000       # 工具输出字符数阈值
```

## 使用示例

### 自动压缩

压缩是自动触发的，无需手动调用：

```python
# 在attacker_node中自动调用
compressor = ContextCompressor(llm_client=attacker_llm_client)
messages = compressor.compress_messages(messages, keep_recent=5)
```

### 手动提取关键信息

```python
from src.utils.context_compressor import ContextCompressor

compressor = ContextCompressor()
key_info = compressor.extract_key_information(messages)

print(key_info["flags_found"])  # 找到的FLAG
print(key_info["tools_used"])    # 使用的工具
print(key_info["errors"])        # 错误信息
```

## 压缩效果

**压缩前**：
- 30条消息，15000字符
- 包含大量重复和冗余信息

**压缩后**：
- 7条消息（1条系统消息 + 1条总结 + 5条最近消息）
- 约3000字符
- 保留所有关键信息

## 注意事项

1. **LLM总结需要API调用**：如果LLM总结失败，会自动回退到简单总结
2. **关键信息优先**：压缩时会优先保留FLAG、错误等关键信息
3. **可配置性**：所有阈值都可以通过环境变量调整

## 未来优化

- [ ] 更智能的总结策略
- [ ] 支持多种压缩算法
- [ ] 压缩效果评估
- [ ] 自适应阈值调整

