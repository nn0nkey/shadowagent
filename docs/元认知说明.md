# 元认知（Meta-Cognition）机制说明

## 功能概述

元认知机制让Agent能够：
1. **自我评估**：评估自己对当前策略的信心水平
2. **自我反思**：反思自己的决策和行动
3. **策略调整**：根据信心水平自动调整策略

## 核心功能

### 1. 信心评估（Confidence Assessment）

**参考Cyber-AutoAgent实现**：
- 使用数值信心（0-100%），不是等级
- 每次操作后立即更新
- 明确的更新公式

**信心更新公式**（参考Cyber-AutoAgent）：
- **成功**: +20%
- **失败**: -30%
- **模糊/部分**: -10%

**信心等级划分**（参考Cyber-AutoAgent）：
- **High (高)**: ≥ 80%
  - 策略：直接使用专业工具执行（nmap, sqlmap等）
- **Medium (中)**: 50-80%
  - 策略：假设测试，可以并行探索
- **Low (低)**: < 50%
  - 策略：信息收集，切换策略或咨询顾问

**评估方式**：
1. **简单评估**（默认）：基于规则的快速评估
2. **LLM评估**（可选）：使用LLM进行深度评估
3. **更新公式**：每次操作后自动应用公式更新

### 2. 自我反思（Self-Reflection）

**反思内容**：
- 分析失败模式
- 识别操作问题
- 总结经验教训
- 提供下一步建议

**触发时机**：
- 操作失败时自动触发
- 连续失败时深度反思

### 3. 策略调整（Strategy Adjustment）

**基于信心水平的决策**：
- **高信心**：直接执行，不咨询顾问
- **中信心**：继续执行，但关注结果
- **低信心**：自动咨询顾问

## 工作流程

```
工具执行完成
    ↓
元认知评估
    ├─ 评估信心水平
    ├─ 自我反思（如果失败）
    └─ 更新状态
        ↓
根据信心水平决策
    ├─ 低信心 → 咨询顾问
    ├─ 中信心 → 继续执行（但关注）
    └─ 高信心 → 直接执行
```

## 配置参数

在 `.env` 文件中配置：

```bash
# 启用元认知（默认开启）
ENABLE_METACOGNITION=true

# 使用LLM进行深度评估（可选，默认使用规则评估）
USE_LLM_METACOGNITION=false
```

## 使用示例

### 场景1：高信心继续执行（参考Cyber-AutoAgent）

```
初始信心: 50%
操作1: execute_command("nmap ...") → ✅
信心更新: 50% + 20% = 70%
操作2: execute_python_poc("...") → ✅
信心更新: 70% + 20% = 90%

元认知评估：
- 信心分数: 90% (HIGH)
- 策略: 直接使用专业工具执行
- 决策: 继续执行，不咨询顾问
```

### 场景2：低信心咨询顾问（参考Cyber-AutoAgent）

```
初始信心: 50%
操作1: execute_command("nmap ...") → ❌
信心更新: 50% - 30% = 20%
操作2: execute_command("nmap ...") → ❌
信心更新: 20% - 30% = 0% (限制在0%)
操作3: execute_command("nmap ...") → ❌
信心更新: 0% - 30% = 0% (已到下限)

元认知评估：
- 信心分数: 0% (LOW)
- 更新公式: "50% - 30% = 20%, 20% - 30% = 0%"
- 策略: 信息收集，切换策略或咨询顾问
- 反思: "已连续失败3次，当前策略可能不适合。需要尝试不同的攻击方法。"
- 决策: 自动咨询顾问（<50%阈值）
```

### 场景3：自我反思

```
操作失败后：
- 反思: "遇到404错误，可能是路径或参数错误。"
- 经验: ["需要重新检查目标路径和参数"]
- 建议: "可以继续尝试，但需要调整方法"
```

## 状态字段

元认知相关的状态字段（参考Cyber-AutoAgent）：

```python
{
    "confidence_score": 0-100,              # 数值信心（0-100%，参考Cyber-AutoAgent）
    "confidence_level": "high|medium|low",    # 信心等级（用于显示）
    "confidence_update_formula": "70% - 30% = 40%",  # 更新公式
    "last_reflection": "反思内容"            # 最后一次反思
}
```

## 优势

### 传统路由 vs 元认知路由

| 特性 | 传统路由 | 元认知路由 |
|------|---------|-----------|
| 决策依据 | 固定规则 | 动态信心评估 |
| 自我反思 | ❌ | ✅ |
| 策略调整 | 固定 | 自适应 |
| 效率 | 一般 | 更高 |

### 实际效果

1. **减少无效尝试**：低信心时及时咨询，避免浪费
2. **提高成功率**：高信心时直接执行，提高效率
3. **自我改进**：通过反思不断优化策略

## 未来优化

- [ ] 更细粒度的信心评估维度
- [ ] 学习历史成功模式
- [ ] 预测性信心评估
- [ ] 多维度反思（技术、策略、工具选择等）

