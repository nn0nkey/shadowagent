"""
HTTP å“åº”è§£æå™¨

è§£æ curlã€requests ç­‰å·¥å…·çš„ HTTP å“åº”è¾“å‡º
"""
import re
from typing import List
from .base import BaseOutputParser, ParsedOutput


class HttpParser(BaseOutputParser):
    """HTTP å“åº”è§£æå™¨"""
    
    tool_name = "http"
    tool_patterns = ["HTTP/", "Status:", "Content-Type:", "<!DOCTYPE", "<html"]
    
    def __init__(self):
        super().__init__()
        # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯ä¾èµ–
        self._extractor = None
    
    @property
    def extractor(self):
        """å»¶è¿ŸåŠ è½½è§„åˆ™æå–å™¨"""
        if self._extractor is None:
            try:
                from src.utils.rule_based_extractor import get_extractor
                self._extractor = get_extractor()
            except Exception:
                self._extractor = None
        return self._extractor
    
    def parse(self, output: str) -> ParsedOutput:
        result = ParsedOutput(tool_name=self.tool_name)
        
        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨è§„åˆ™æå–å™¨æå–å…³é”®ä¿¡æ¯ï¼ˆæ–°å¢ï¼‰â­
        if self.extractor and len(output) > 100:  # åªå¯¹è¾ƒé•¿çš„è¾“å‡ºä½¿ç”¨è§„åˆ™æå–
            try:
                extracted = self.extractor.extract(output, scope='critical')
                self._merge_extracted_info(result, extracted)
            except Exception as e:
                pass  # é™çº§åˆ°åŸæœ‰é€»è¾‘
        
        # æå–FLAG
        result.flags = self._extract_flags(output)
        
        # æå–çŠ¶æ€ç 
        status_patterns = [
            r'HTTP/[\d.]+\s+(\d+)\s*(\w*)',
            r'Status:\s*(\d+)',
            r'status_code[:\s]+(\d+)',
        ]
        
        for pattern in status_patterns:
            match = re.search(pattern, output, re.IGNORECASE)
            if match:
                status = match.group(1)
                result.findings.append(f"HTTP Status: {status}")
                break
        
        # æå–å…³é”®å“åº”å¤´
        header_patterns = [
            (r'Server:\s*(.+)', "Server"),
            (r'X-Powered-By:\s*(.+)', "X-Powered-By"),
            (r'Set-Cookie:\s*([^;\n]+)', "Cookie"),
            (r'Location:\s*(.+)', "Redirect"),
            (r'Content-Type:\s*(.+)', "Content-Type"),
            (r'X-Frame-Options:\s*(.+)', "X-Frame-Options"),
        ]
        
        for pattern, label in header_patterns:
            matches = re.findall(pattern, output, re.IGNORECASE)
            for match in matches[:3]:
                value = match.strip()
                if label in ["Server", "X-Powered-By"]:
                    result.tech_stack.append(value)
                result.findings.append(f"{label}: {value}")
        
        # æå–é“¾æ¥
        link_patterns = [
            r'href=["\']([^"\']+)["\']',
            r'action=["\']([^"\']+)["\']',
            r'src=["\']([^"\']+\.(?:php|jsp|asp|js))["\']',
        ]
        
        seen_urls = set()
        for pattern in link_patterns:
            matches = re.findall(pattern, output, re.IGNORECASE)
            for url in matches:
                if url not in seen_urls and not url.startswith(('#', 'javascript:', 'data:')):
                    seen_urls.add(url)
                    result.urls.append(url)
        
        # æå–è¡¨å•
        form_pattern = r'<form[^>]*action=["\']([^"\']*)["\'][^>]*method=["\']?(\w+)["\']?'
        forms = re.findall(form_pattern, output, re.IGNORECASE)
        for action, method in forms:
            result.findings.append(f"è¡¨å•: {method.upper()} {action}")
        
        # æå–è¾“å…¥å­—æ®µ
        input_pattern = r'<input[^>]*name=["\']([^"\']+)["\'][^>]*type=["\']?(\w+)["\']?'
        inputs = re.findall(input_pattern, output, re.IGNORECASE)
        input_names = [f"{name}({type_})" for name, type_ in inputs]
        if input_names:
            result.findings.append(f"è¾“å…¥å­—æ®µ: {', '.join(input_names[:10])}")
        
        # æå–æ³¨é‡Šä¸­çš„ä¿¡æ¯
        comment_pattern = r'<!--(.+?)-->'
        comments = re.findall(comment_pattern, output, re.DOTALL)
        for comment in comments[:3]:
            comment_clean = comment.strip()[:100]
            if comment_clean and len(comment_clean) > 5:
                result.findings.append(f"HTMLæ³¨é‡Š: {comment_clean}")
        
        # æå–é”™è¯¯ä¿¡æ¯
        error_patterns = [
            r'(?:error|exception|warning):\s*(.+)',
            r'(?:SQL syntax|mysql_|pg_|sqlite_)(.+)',
            r'(?:Parse error|Fatal error):\s*(.+)',
        ]
        
        for pattern in error_patterns:
            matches = re.findall(pattern, output, re.IGNORECASE)
            for match in matches[:3]:
                result.errors.append(match[:200])
        
        if result.errors:
            result.success = False
        
        return result
    
    def _merge_extracted_info(self, result: ParsedOutput, extracted: dict):
        """å°†è§„åˆ™æå–çš„ä¿¡æ¯åˆå¹¶åˆ°ç»“æœä¸­"""
        # å‡­è¯ä¿¡æ¯
        for cred in extracted.get('credentials', []):
            if 'username' in cred and 'password' in cred:
                result.findings.append(
                    f"ğŸ”‘ å‘ç°å‡­è¯: {cred['username']}:{cred['password']} (æ¥æº: {cred['source']})"
                )
            elif 'type' in cred:
                result.findings.append(
                    f"ğŸ”‘ è®¤è¯ä¿¡æ¯: {cred['type']} {cred.get('value', '')[:50]}"
                )
        
        # ææƒå­—æ®µ
        for field in extracted.get('privilege_fields', []):
            bypassable = " (disabledï¼Œå¯ç»•è¿‡)" if field.get('bypassable') else ""
            result.findings.append(
                f"âš ï¸ ææƒå­—æ®µ: {field['field']}{bypassable}"
            )
        
        # IDOR ç‚¹
        for idor in extracted.get('idor_points', []):
            result.findings.append(
                f"ğŸ¯ IDOR æ”»å‡»ç‚¹: ID={idor['id']} ({idor['type']})"
            )
        
        # API ç«¯ç‚¹
        for api in extracted.get('api_endpoints', []):
            param_note = " (æœ‰å‚æ•°)" if api.get('has_param') else ""
            result.urls.append(api['endpoint'])
            result.findings.append(f"ğŸ”— API: {api['endpoint']}{param_note}")
        
        # æ¼æ´æŒ‡ç¤ºå™¨
        for vuln in extracted.get('vulnerabilities', []):
            result.findings.append(
                f"âš¡ æ¼æ´æŒ‡ç¤ºå™¨: {vuln['type']} - {vuln['indicator'][:50]}"
            )
        
        # æç¤ºä¿¡æ¯
        for hint in extracted.get('hints', []):
            result.findings.append(
                f"ğŸ’¡ æç¤º: {hint['content'][:100]}"
            )
